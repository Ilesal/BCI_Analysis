{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG based Brain-Computer Interface using Visual Imagery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Cognitive Neuroscience 2020/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Pre-Processing Analysis\n",
    "\n",
    "1. Import libraries\n",
    "2. Load dataset\n",
    "3. Remove unwanted channels\n",
    "4. Bandpass filter the data\n",
    "5. Create Epochs\n",
    "6. Artefact Correction with Independent Compontent Analysis (ICA)\n",
    "7. Automatic bad epochs rejections (MNE Autoreject)\n",
    "8. Save dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture libraries   \n",
    "\n",
    "import sys\n",
    "import os\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install mne\n",
    "!{sys.executable} -m pip install mne-features\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import pathlib\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne import Epochs, create_info, events_from_annotations\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs,corrmap\n",
    "from mne.time_frequency import tfr_morlet, psd_multitaper, psd_welch, tfr_stockwell,tfr_multitaper,tfr_array_morlet,AverageTFR\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "matplotlib.use('Qt5Agg') #allow interactive plots\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import GeneralizingEstimator, Scaler,cross_val_multiscore, LinearModel, get_coef, Vectorizer, CSP, SlidingEstimator\n",
    "from mne.viz import centers_to_edges\n",
    "from mne.baseline import rescale\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold, ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support, precision_recall_curve, average_precision_score, plot_precision_recall_curve, ConfusionMatrixDisplay, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import plot_roc_curve, accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from autoreject import get_rejection_threshold\n",
    "from autoreject import AutoReject\n",
    "%run SM1.ipynb import load_data, excl_chan, filter_data, make_epochs, plot_data, epochs_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the raw EEG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_data(os.getcwd()); #30 sessions in .edf format will be uploaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exclude unwanted channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_channels = ['AF3','F7','F3','FC5','T7','P7','O1','O2','P8','T8','FC6','F4','F8','AF4']; #reference_channels = ['CQ_CMS', 'CQ_DRL']\n",
    "excl_chan(raw_datasets) #remove the channels not included in the above list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the unfiltered power spectrum density (PSD) from one session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets[1].plot_psd(average=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply Band-Pass Filter between 1-30Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the power spectrum of the filtered dataset, to check if the power line noise has been filtered out\n",
    "raw_datasets[1].plot_psd(average=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each epoch has a duration of 9.5 seconds. The first and last 250 milliseconds have been removed to avoid overlap between the events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoched_data=make_epochs(raw_datasets, 10) \n",
    "print(epoched_data.get_data().shape) #the final shape is n_epochs, chans, samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoched_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Apply ICA to the epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = raw_datasets[0].info['ch_names'] #define the eeg channels we want to include in the analysis, in this case all of them\n",
    "ica=ICA(n_components=2, method='fastica', max_iter=10000, random_state=89) #define the parameters\n",
    "ica.fit(epoched_data,  picks = picks, reject = dict(eeg = 200e-6)) #apply ICA to epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot ICA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components(picks=range(2), inst=epoched_data)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the components to exclude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude=[0,1,13] #exclude eye movements, heartbeat and saccade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before excluding the above identified ICA components, check also their time courses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_sources(epoched_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems that also ICA components 7 and 8 might be problematic, use plot_overlay to overlay the raw and cleaned signals and see if by exlcuding these further two components there is a substantial difference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoevo=epoched_data.average() #create an evoked object\n",
    "ica.plot_overlay(epoevo, exclude=[0,1,13], picks='eeg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_overlay(epoevo, exclude=[0,1,13,7,8], picks='eeg')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The signal didn't change after the removal of components 7 and 8. \n",
    "#### Exclude the components earlier identified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.apply(epoched_data, exclude=ica.exclude)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Reject Bad Epochs using MNE function Autoreject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = AutoReject()\n",
    "epochs = ar.fit_transform(epoched_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoreject import get_rejection_threshold\n",
    "reject = get_rejection_threshold(epoched_data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Time-Frequency Analysis using Morlet Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.logspace(*np.log10([2, 30]), num=40) # define frequencies of interest (log-spaced) \n",
    "n_cycles = freqs / 2.  # different number of cycle per frequency\n",
    "\n",
    "\n",
    "#Compute power RELAX condition\n",
    "power = mne.time_frequency.tfr_morlet(epochs, freqs=freqs, n_cycles=n_cycles, \n",
    "                                           use_fft=True, average=False,\n",
    "                                           return_itc=False, decim=3, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract TFR features in Alpha band (8-12Hz)\n",
    "\n",
    "n_col= power.data.shape[3] #extract n columns from pw output\n",
    "n_chan=power.data.shape[1] #extract n channels\n",
    "n_row= power.data.shape[0] #extract n rows\n",
    "\n",
    "alpha_pow = np.zeros(shape=(n_row,n_chan,n_col))   \n",
    "counter=0\n",
    "for samples in range (0,n_row):\n",
    "    for chan in range(0, n_chan): \n",
    "        pow_a = power.data[samples][chan][(power.freqs>=8) & (power.freqs<12)][:]  \n",
    "        counter+=1\n",
    "        pow_avg_a = np.mean(pow_a, axis=0)  \n",
    "        alpha_pow[samples,chan,:]=pow_avg_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, initialise the below variables to store the accuracies from all classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, f1_scores = [], []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Split the dataset into training and testing with a 70:30 ratio (Training:Test):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= alpha_pow   \n",
    "labels = epochs.events[:,-1] #our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training and testing data\n",
    "train_data, test_data, labels_train, labels_test = train_test_split(data, labels, test_size=0.30, random_state=37) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm_pip = make_pipeline(Vectorizer(), StandardScaler(), svm.SVC(probability=True))  #define pipeline\n",
    "parameters = {'svc__kernel':['linear', 'rbf', 'sigmoid'], 'svc__C':[0.1, 1, 10], 'svc__gamma':[0.1,0.01,0.001]}\n",
    "#Apply GridSearchCV to identify the best parameters\n",
    "gs_cv_svm = GridSearchCV(clf_svm_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=10), return_train_score=True) \n",
    "\n",
    "#Training is done by passing the training data and their labels to fit() function.\n",
    "\n",
    "gs_cv_svm.fit(train_data, labels_train)\n",
    "print('Best Parameters: {}'.format(gs_cv_svm.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_svm.best_score_))\n",
    "\n",
    "\n",
    "predictions_svm = gs_cv_svm.predict(test_data)\n",
    "\n",
    "#Evaluate\n",
    "report_svm = classification_report(labels_test, predictions_svm, target_names=['Relax', 'Push'])\n",
    "print('SVM Clasification Report:\\n {}'.format(report_svm))\n",
    "\n",
    "acc_svm = accuracy_score(labels_test, predictions_svm)\n",
    "print(\"Accuracy of SVM model: {}\".format(acc_svm))\n",
    "\n",
    "precision_svm,recall_svm,fscore_svm,support_svm=precision_recall_fscore_support(labels_test,predictions_svm,average='macro')\n",
    "print('Precision: {0}, Recall: {1}, f1-score:{2}'.format(precision_svm,recall_svm,fscore_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area Under Curve (AUC) value\n",
    "auc = roc_auc_score(labels_test, predictions_svm)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_roc = plot_roc_curve(gs_cv_svm, test_data, labels_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pr = plot_precision_recall_curve(gs_cv_svm, test_data, labels_test) #precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "errors_svc = abs(predictions_svm - labels_test)\n",
    "print('Average absolute error:', round(np.mean(errors_svc), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lda_pip = make_pipeline(Vectorizer(), StandardScaler(), LinearDiscriminantAnalysis())\n",
    "parameters = {'lineardiscriminantanalysis__solver':['svd']}\n",
    "gs_cv_lda = GridSearchCV(clf_lda_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=10), return_train_score=True) \n",
    "gs_cv_lda.fit(train_data,labels_train)\n",
    " \n",
    "print('Best Parameters: {}'.format(gs_cv_lda.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_lda.best_score_))\n",
    "\n",
    "\n",
    "#Predictions\n",
    "predictions_lda = gs_cv_lda.predict(test_data)\n",
    "\n",
    "#Evaluation\n",
    "report_lda = classification_report(labels_test, predictions_lda, target_names=['Relax', 'Push'])\n",
    "print('LDA Clasification Report:\\n {}'.format(report_lda))\n",
    "\n",
    "acc_lda = accuracy_score(labels_test, predictions_lda)\n",
    "print(\"Accuracy of LDA model: {}\".format(acc_lda))\n",
    "\n",
    "precision_lda,recall_lda,fscore_lda,support_lda=precision_recall_fscore_support(labels_test,predictions_lda,average='macro')\n",
    "print('Precision: {0}, Recall: {1}, f1-score:{2}'.format(precision_lda,recall_lda,fscore_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area Under Curve (AUC) value\n",
    "auc = roc_auc_score(labels_test, predictions_lda)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC \n",
    "lda_roc = plot_roc_curve(gs_cv_lda, test_data, labels_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision-Recall \n",
    "lda_pr = plot_precision_recall_curve(gs_cv_lda,test_data, labels_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "errors_lda = abs(predictions_lda - labels_test)\n",
    "print('Average absolute error:', round(np.mean(errors_lda), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr_pip = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(max_iter=5000))\n",
    "parameters ={'logisticregression__C': np.logspace(0, 4, 100)}  \n",
    "\n",
    "\n",
    "gs_cv_lr = GridSearchCV(clf_lr_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=10))\n",
    "gs_cv_lr.fit(train_data, labels_train)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_lr.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_lr.best_score_))\n",
    "\n",
    "#Predictions\n",
    "predictions_lr = gs_cv_lr.predict(test_data)\n",
    "\n",
    "#Evaluation\n",
    "report_lr = classification_report(labels_test, predictions_lr, target_names=['Relax', 'Push'])\n",
    "print('LR Clasification Report:\\n {}'.format(report_lr))\n",
    "\n",
    "acc_lr = accuracy_score(labels_test, predictions_lr)\n",
    "print(\"Accuracy of LR model: {}\".format(acc_lr))\n",
    "\n",
    "precision_lr,recall_lr,fscore_lr,support_lr=precision_recall_fscore_support(labels_test,predictions_lr,average='macro')\n",
    "print('Precision: {0}, Recall: {1}, f1-score:{2}'.format(precision_lr,recall_lr,fscore_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area Under Curve (AUC) value\n",
    "auc = roc_auc_score(labels_test, predictions_lr)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "lr_roc = plot_roc_curve(gs_cv_lr, test_data, labels_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "lr_pr = plot_precision_recall_curve(gs_cv_lr, test_data, labels_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "errors_lr = abs(predictions_lr - labels_test)\n",
    "print('Average absolute error:', round(np.mean(errors_lr), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_pip = make_pipeline(Vectorizer(), StandardScaler(), RandomForestClassifier()) \n",
    "parameters = {'randomforestclassifier__n_estimators':[100,200,300,400,500,600,700], 'randomforestclassifier__criterion':['gini', 'entropy'], 'randomforestclassifier__max_depth':[1,2,3,4,5]} \n",
    "gs_cv_rf = GridSearchCV(clf_rf_pip, parameters, scoring='accuracy', cv=StratifiedKFold(n_splits=10), return_train_score=True)  \n",
    "gs_cv_rf.fit(train_data,labels_train)\n",
    "\n",
    "print('Best Parameters: {}'.format(gs_cv_rf.best_params_))\n",
    "print('Best Score: {}'.format(gs_cv_rf.best_score_))\n",
    "\n",
    "predictions_rf = gs_cv_rf.predict(test_data)\n",
    "\n",
    "#Evaluation\n",
    "report_rf = classification_report(labels_test, predictions_rf, target_names=['Relax', 'Push'])\n",
    "print('RF Clasification Report:\\n {}'.format(report_rf))\n",
    "\n",
    "acc_rf = accuracy_score(labels_test, predictions_rf)\n",
    "print(\"Accuracy of RF model: {}\".format(acc_rf))\n",
    "\n",
    "precision_rf,recall_rf,fscore_rf,support_rf=precision_recall_fscore_support(labels_test,predictions_rf,average='macro')\n",
    "print('Precision: {0}, Recall: {1}, f1-score:{2}'.format(precision_rf,recall_rf,fscore_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area Under Curve (AUC) value\n",
    "auc = roc_auc_score(labels_test, predictions_rf)\n",
    "print('ROC AUC: %f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "rf_roc = plot_roc_curve(gs_cv_rf, test_data, labels_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision\n",
    "rf_pr = plot_precision_recall_curve(gs_cv_rf, test_data, labels_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "errors_rf = abs(predictions_rf - labels_test)\n",
    "print('Average absolute error:', round(np.mean(errors_rf), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all classifier perfomance\n",
    "accuracies.append([acc_svm, acc_lda, acc_lr, acc_rf])\n",
    "f1_scores.append([fscore_svm, fscore_lda, fscore_lr, fscore_rf ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Roc Curve Comparison\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "svm_roc.plot(ax=ax, alpha=0.8,label='SVM')\n",
    "lda_roc.plot(ax=ax, alpha=0.8,label='LDA')    \n",
    "lr_roc.plot(ax=ax, alpha=0.8,label='LR')       \n",
    "rf_roc.plot(ax=ax, alpha=0.8,label='RF')\n",
    "\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision-Recall curve\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "svm_pr.plot(ax=ax, alpha=0.8,label='SVM')\n",
    "lda_pr.plot(ax=ax, alpha=0.8,label='LDA')\n",
    "lr_pr.plot(ax=ax, alpha=0.8,label='LR')\n",
    "rf_pr.plot(ax=ax, alpha=0.8,label='RF')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(accuracies)) #the final shape should be (3,4)\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_scores)#check the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy scores\n",
    "\n",
    " \n",
    "barWidth = 3 # Choose the width of the bars\n",
    "\n",
    "\n",
    "bars1 = [row[0] for row in accuracies ]  #SVM\n",
    "bars2 = [row[1] for row in accuracies ]  #LDA\n",
    "bars3 = [row[2] for row in accuracies ]  #LR\n",
    "bars4 = [row[3] for row in accuracies ]  #RF\n",
    " \n",
    "\n",
    "\n",
    "# The x position of bars\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "r5 = [x + barWidth for x in r4]\n",
    "\n",
    "\n",
    "# Create the bars\n",
    "ax = plt.axes()\n",
    "plt.bar(r1, bars1, color='#87CEFA', width=1, edgecolor='white', label='SVM')\n",
    "plt.bar(r2, bars2, color='#FFE4E1', width=1, edgecolor='white', label='LDA')\n",
    "plt.bar(r3, bars3, color='#CD5C5C', width=1, edgecolor='white', label='LR')\n",
    "plt.bar(r4, bars4, color='#C5E384', width=1, edgecolor='white', label='RF')\n",
    "\n",
    "#plt.axhline(y=0.5, color='k', linestyle='--',linewidth=0.4)\n",
    "plt.xlabel('Classification Tasks')\n",
    "plt.ylabel(' Accuracies')\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(0.98, 1))\n",
    "plt.xticks([], [])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
